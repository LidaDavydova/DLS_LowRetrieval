{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8473895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d90cce",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/ruslawod300000.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read each dataset chunk\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset/ruslawod300000.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# change name by hand\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/data/inno_courses/DLS/.venv/lib/python3.10/site-packages/pandas/io/parquet.py:669\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    667\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/data/inno_courses/DLS/.venv/lib/python3.10/site-packages/pandas/io/parquet.py:258\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    257\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    266\u001b[0m         path_or_handle,\n\u001b[1;32m    267\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    271\u001b[0m     )\n",
      "File \u001b[0;32m/media/data/inno_courses/DLS/.venv/lib/python3.10/site-packages/pandas/io/parquet.py:141\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    131\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/media/data/inno_courses/DLS/.venv/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/ruslawod300000.parquet'"
     ]
    }
   ],
   "source": [
    "# read each dataset chunk\n",
    "df = pd.read_parquet(\n",
    "        'dataset/ruslawod30000.parquet', # change name by hand\n",
    "        engine=\"pyarrow\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate classifier_code and classifier_name\n",
    "df[['classifier_code', 'classifier_name']] = df['classifierByIPS'].str.split('$', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9158530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classifier_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49772c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier_level2\n",
       "010.140    4031\n",
       "010.070    1199\n",
       "210.010     658\n",
       "210.020     499\n",
       "020.010     420\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since classifier_code variate too much, we will classify by first 2 numbers of classifier_code\n",
    "df['classifier_level2'] = df['classifier_code'].str.extract(r'^(\\d{3}\\.\\d{3})')\n",
    "\n",
    "# Check distribution\n",
    "df['classifier_level2'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep dataset with index and classifier_level2 for each chunk\n",
    "classifier_code = df[['classifier_level2']]\n",
    "classifier_code.to_parquet('dataset/classifier_code_281233.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05502820",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Concat classifier_code chunks in one dataset '''\n",
    "DATA_DIR = Path(\"dataset/\")     \n",
    "PATTERN = \"classifier_code_*.parquet\" \n",
    "\n",
    "dfs = []\n",
    "for f in DATA_DIR.glob(PATTERN):\n",
    "    df = pd.read_parquet(\n",
    "        f,\n",
    "        engine=\"pyarrow\"\n",
    "    )\n",
    "    dfs.append(df)\n",
    "df_full = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08c2b1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 227290 entries, 0 to 281232\n",
      "Data columns (total 1 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   classifier_level2  227290 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8510564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier_level2\n",
       "010.140    101063\n",
       "010.070     30507\n",
       "210.010     16376\n",
       "210.020     12151\n",
       "020.010     11105\n",
       "            ...  \n",
       "040.020         1\n",
       "060.000         1\n",
       "090.110         1\n",
       "110.080         1\n",
       "070.090         1\n",
       "Name: count, Length: 199, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.classifier_level2.value_counts()\n",
    "# overall 199 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3837da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop empty classifier_level2\n",
    "df_full = df_full.dropna(subset=['classifier_level2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальный размер выборки: (50000, 1)\n",
      "Распределение классов:\n",
      "classifier_level2\n",
      "010.140    0.44468\n",
      "010.070    0.13424\n",
      "210.010    0.07206\n",
      "210.020    0.05346\n",
      "020.010    0.04886\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "code_counts = df_full['classifier_level2'].value_counts()\n",
    "valid_codes = code_counts[code_counts >= 2].index # if code frequency = 1, it considered as outlier\n",
    "df_filtered = df_full[df_full['classifier_level2'].isin(valid_codes)]\n",
    "\n",
    "# make only 50k for easy and fast work with dataset\n",
    "# we want the same distribution, so we use stratify by classifier_level2\n",
    "df_sampled, _ = train_test_split(\n",
    "    df_filtered,\n",
    "    train_size=50000,\n",
    "    stratify=df_filtered['classifier_level2'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b8d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальный размер выборки: (50000, 1)\n",
      "Распределение классов:\n",
      "classifier_level2\n",
      "010.140    0.44468\n",
      "010.070    0.13424\n",
      "210.010    0.07206\n",
      "210.020    0.05346\n",
      "020.010    0.04886\n",
      "            ...   \n",
      "080.090    0.00002\n",
      "200.000    0.00002\n",
      "160.020    0.00002\n",
      "070.050    0.00002\n",
      "120.070    0.00002\n",
      "Name: proportion, Length: 169, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Финальный размер выборки: {df_sampled.shape}\")\n",
    "print(f\"Распределение классов:\\n{df_sampled['classifier_level2'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save 50k indexes with code\n",
    "df_sampled.to_parquet('dataset/sample_50k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b219cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bafb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18842697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
