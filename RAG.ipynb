{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d3512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/inno_courses/DLS/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4937f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('cointegrated/rubert-tiny2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45901bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"embeddings/embeddings.index\")  # read index from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401dd17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"embeddings/embeddings.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a343865d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49727, 312)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5aef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_files = sorted(Path('.').glob('dataset/preproc_data*.parquet'))\n",
    "dfs = [pd.read_parquet(f) for f in chunk_files]\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8e765f",
   "metadata": {},
   "source": [
    "# Ranking metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676b32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(relevant, k):\n",
    "    return np.sum(relevant[:k]) / k\n",
    "\n",
    "def recall_at_k(relevant, total_relevant, k):\n",
    "    if total_relevant == 0:\n",
    "        return 0.0\n",
    "    return np.sum(relevant[:k]) / total_relevant\n",
    "\n",
    "\n",
    "def hits_at_k(relevant, k):\n",
    "    return 1.0 if np.sum(relevant[:k]) > 0 else 0.0\n",
    "\n",
    "def mrr(relevant):\n",
    "    for idx, rel in enumerate(relevant, 1):\n",
    "        if rel:\n",
    "            return 1.0 / idx\n",
    "    return 0.0\n",
    "\n",
    "def dcg(relevant, k):\n",
    "    return np.sum(relevant[:k] / np.log2(np.arange(2, k + 2)))\n",
    "\n",
    "def ndcg_at_k(relevant, k):\n",
    "    ideal_relevant = np.sort(relevant[::-1])\n",
    "    idcg = dcg(ideal_relevant, k)\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    return dcg(relevant, k) / idcg\n",
    "\n",
    "def average_precision_at_k(relevant, k):\n",
    "    hits = 0\n",
    "    sum_precisions = 0.0\n",
    "    for i in range(k):\n",
    "        if relevant[i]:\n",
    "            hits += 1\n",
    "            sum_precisions += hits / (i + 1)\n",
    "    if hits == 0:\n",
    "        return 0.0\n",
    "    return sum_precisions / hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a639af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_index(index, embeddings, df, k=10, n_eval=100):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    hits = []\n",
    "    mrrs = []\n",
    "    ndcgs = []\n",
    "    aps = []\n",
    "\n",
    "    class_counts = df['classifierByIPS'].value_counts().to_dict()\n",
    "\n",
    "    for _ in range(n_eval):\n",
    "        # choose random query from embedding\n",
    "        i = np.random.randint(0, len(embeddings))\n",
    "        query = embeddings[i].reshape(1, -1)\n",
    "        query_class = df.iloc[i]['classifierByIPS']\n",
    "\n",
    "        if not isinstance(query_class, str) or query_class == \"UNKNOWN\":\n",
    "            continue\n",
    "\n",
    "        _, topk = index.search(query, k+1)\n",
    "        topk = topk[0][1:]  # except the same one\n",
    "\n",
    "        topk_classes = df.iloc[topk]['classifierByIPS'].values\n",
    "        relevant = (topk_classes == query_class).astype(int)\n",
    "\n",
    "        precisions.append(precision_at_k(relevant, k))\n",
    "        total_relevant = class_counts.get(query_class, 0) - 1\n",
    "        total_relevant = max(total_relevant, 0)\n",
    "        recalls.append(recall_at_k(relevant, total_relevant, k))\n",
    "        hits.append(hits_at_k(relevant, k))\n",
    "        mrrs.append(mrr(relevant))\n",
    "        ndcgs.append(ndcg_at_k(relevant, k))\n",
    "        aps.append(average_precision_at_k(relevant, k))\n",
    "\n",
    "    print(\"Evaluation results:\")\n",
    "    print(f\"Precision@{k}: {np.mean(precisions):.3f}\")\n",
    "    print(f\"Recall@{k}: {np.mean(recalls):.3f}\")\n",
    "    print(f\"Hits@{k}:     {np.mean(hits):.3f}\")\n",
    "    print(f\"MRR:          {np.mean(mrrs):.3f}\")\n",
    "    print(f\"NDCG@{k}:     {np.mean(ndcgs):.3f}\")\n",
    "    print(f\"MAP@{k}:      {np.mean(aps):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014181f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "Precision@10: 0.107\n",
      "Recall@10: 0.034\n",
      "Hits@10:     0.259\n",
      "MRR:          0.214\n",
      "NDCG@10:     0.509\n",
      "MAP@10:      0.196\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluate_index(index, embeddings, df, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3faca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.3235719203948975"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def measure_faiss_speed(index, embeddings, n_queries=100):\n",
    "    total_time = 0.0\n",
    "    for _ in range(n_queries):\n",
    "        i = np.random.randint(0, len(embeddings))\n",
    "        query = embeddings[i].reshape(1, -1)\n",
    "        start = time.time()\n",
    "        _ = index.search(query, 10)\n",
    "        total_time += time.time() - start\n",
    "    avg_time_ms = (total_time / n_queries) * 1000\n",
    "    return avg_time_ms\n",
    "measure_faiss_speed(index, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb19a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real query test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42595e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"–∏–º—É—â–µ—Å—Ç–≤–æ –∞—ç—Ä–æ–ø–æ—Ä—Ç–∞\"\n",
    "query_vec = model.encode([query])\n",
    "query_vec = query_vec / np.linalg.norm(query_vec)\n",
    "\n",
    "faiss.normalize_L2(query_vec)\n",
    "\n",
    "# –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö\n",
    "k = 50  # –ë–æ–ª—å—à–µ, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å\n",
    "\n",
    "distances, indices = index.search(query_vec, k)\n",
    "\n",
    "grouped = defaultdict(list)\n",
    "for i, dist in zip(indices[0], distances[0]):\n",
    "    if i == -1: continue\n",
    "    row = df.iloc[i]\n",
    "    classifier = str(row['classifierByIPS']).strip() if pd.notna(row['classifierByIPS']) else \"UNKNOWN\"\n",
    "    grouped[classifier].append((i, dist))\n",
    "\n",
    "# 5. –í—ã–≤–æ–¥ ‚Äî –ø–æ 3 –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ –∫–ª–∞—Å—Å\n",
    "print(f\"\\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}' (–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ classifierByIPS):\\n\")\n",
    "for cls, items in grouped.items():\n",
    "    print(f\"\\nüìÇ –ö–ª–∞—Å—Å: {cls} (–≤—Å–µ–≥–æ {len(items)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤):\")\n",
    "    for i, dist in items[:3]:\n",
    "        print(f\"  ‚Ü™ –°—Ö–æ–¥—Å—Ç–≤–æ: {dist:.3f} | ID: {i}\")\n",
    "        print(df.iloc[i]['textIPS'][:200], \"\\n\")\n",
    "\n",
    "# ids, distances = index.knnQuery(query_vec, k=k)\n",
    "\n",
    "# # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª–∞—Å—Å—É\n",
    "# results = []\n",
    "# for idx, dist in zip(ids, distances):\n",
    "#     row = df.iloc[idx]\n",
    "#     classifier = row['classifierByIPS']\n",
    "#     if classifier and isinstance(classifier, str) and classifier.strip().lower() != \"unknown\":\n",
    "#         similarity = 1 - dist  # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ cosine similarity\n",
    "#         results.append({\n",
    "#             \"similarity\": similarity,\n",
    "#             \"classifier\": classifier.strip(),\n",
    "#             \"text\": row['textIPS'][:300],  # –æ–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç\n",
    "#             \"full_index\": idx\n",
    "#         })\n",
    "\n",
    "# # 8. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –≤—ã–≤–æ–¥\n",
    "# top_filtered = sorted(results, key=lambda x: -x['similarity'])[:10]\n",
    "\n",
    "# print(f\"–¢–æ–ø-10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ classifierByIPS (–Ω–µ –ø—É—Å—Ç–æ–π, –Ω–µ unknown):\\n\")\n",
    "# for i, res in enumerate(top_filtered):\n",
    "#     print(f\"‚Äî #{i+1} | –°—Ö–æ–¥—Å—Ç–≤–æ: {res['similarity']:.3f} | –ö–ª–∞—Å—Å: {res['classifier']}\")\n",
    "#     print(res['text'], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f7113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
